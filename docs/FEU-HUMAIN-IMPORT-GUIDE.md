# Guide d'Import FEU HUMAIN

## üìã Pr√©requis

1. **Installer la d√©pendance n√©cessaire** :

```bash
npm install --save-dev formdata-node
```

2. **S'assurer que le projet est en mode d√©veloppement local** :

```bash
npm run dev
```

Ou si vous voulez importer directement en production (non recommand√© pour le premier test).

## üöÄ Utilisation du Script d'Import

### √âtape 1 : Pr√©parer vos donn√©es

Assurez-vous d'avoir :

- Le fichier `message_1.json` de votre export Facebook Messenger
- Les dossiers de m√©dias (`photos/`, `videos/`, `audio_files/`, `gifs/`) - nous les traiterons plus tard

### √âtape 2 : Lancer l'import en local

Pour importer depuis votre serveur local (recommand√© pour tester) :

```bash
# Depuis la racine du projet
npm run import:feu-humain -- /chemin/vers/message_1.json
```

Par exemple :

```bash
npm run import:feu-humain -- ~/Downloads/facebook-export/messages/inbox/FEU\ HUMAIN/message_1.json
```

### √âtape 3 : Suivre le processus

Le script va :

1. **Analyser le fichier** : Compter les messages, d√©tecter les doublons
2. **Demander confirmation** : Vous montrer combien de messages seront import√©s
3. **Importer par chunks** : Diviser l'import en petits morceaux de 100 messages
4. **Afficher une barre de progression** : Vous montrer l'avancement en temps r√©el
5. **G√©rer les reprises** : Si l'import √©choue, vous pourrez le reprendre o√π il s'est arr√™t√©

### √âtape 4 : En cas d'interruption

Si l'import est interrompu (erreur r√©seau, timeout, etc.), relancez simplement la m√™me commande :

```bash
npm run import:feu-humain -- /chemin/vers/message_1.json
```

Le script d√©tectera automatiquement o√π il s'√©tait arr√™t√© et vous proposera de reprendre.

## ‚ö° Import en Production

**‚ö†Ô∏è ATTENTION** : L'import direct en production peut √™tre plus lent et sujet aux timeouts.

Pour importer directement sur la base de donn√©es de production :

```bash
# Assurez-vous d'avoir les bonnes variables d'environnement
export NEXT_PUBLIC_URL=https://athanor-philosophy-platform.vercel.app

# Lancez l'import
npm run import:feu-humain -- /chemin/vers/message_1.json
```

## üéØ Strat√©gie Recommand√©e

1. **Testez d'abord en local** :
   - Lancez `npm run dev`
   - Importez quelques messages pour tester
   - V√©rifiez que tout fonctionne sur `http://localhost:3000/admin/feu-humain`

2. **Puis importez en production** :
   - Une fois que vous √™tes s√ªr que √ßa marche
   - Utilisez le script avec l'URL de production
   - Laissez tourner (peut prendre 10-20 minutes pour 5800 messages)

## üìä Estimation du Temps

- **En local** : ~2-5 minutes pour 5800 messages
- **En production** : ~15-30 minutes (d√©pend de la latence r√©seau)

Le script traite environ 100 messages toutes les 5-10 secondes pour √©viter les timeouts.

## üõ†Ô∏è D√©pannage

### Erreur "Cannot find module 'formdata-node'"

```bash
npm install --save-dev formdata-node
```

### Erreur "ENOENT: no such file or directory"

V√©rifiez le chemin vers votre fichier `message_1.json`

### Erreur "401 Unauthorized"

Assurez-vous d'√™tre connect√© en tant qu'admin sur l'interface web

### Timeout ou erreur r√©seau

Le script r√©essayera automatiquement 3 fois. Si √ßa √©choue encore, relancez le script - il reprendra o√π il s'est arr√™t√©.

## üì∏ Gestion des M√©dias (Phase 2)

Une fois les messages import√©s, nous traiterons les m√©dias s√©par√©ment :

1. **Option A : Upload manuel** (simple mais fastidieux)
   - Uploadez les m√©dias sur Cloudinary via l'interface
   - Mettez √† jour les URLs dans la base de donn√©es

2. **Option B : Script d'upload de m√©dias** (√† d√©velopper)
   - Script s√©par√© pour uploader tous les m√©dias
   - Mise √† jour automatique des r√©f√©rences

3. **Option C : Servir les m√©dias localement** (pour test uniquement)
   - Placer les m√©dias dans `public/FEU HUMAIN/`
   - Fonctionne uniquement en local

## ‚úÖ V√©rification Post-Import

Apr√®s l'import, v√©rifiez que tout fonctionne :

1. Allez sur `/admin/feu-humain`
2. V√©rifiez les statistiques (nombre de messages, participants)
3. Testez la recherche et les filtres
4. Naviguez dans la timeline

## üîß Configuration Avanc√©e

Le script utilise ces variables d'environnement :

- `NEXT_PUBLIC_URL` : URL de base de l'API (d√©faut: http://localhost:3000)
- `DATABASE_URL` : Connexion √† la base de donn√©es (depuis .env.local)

Vous pouvez modifier ces constantes dans le script :

- `CHUNK_SIZE` : Nombre de messages par chunk (d√©faut: 100)
- `RETRY_ATTEMPTS` : Nombre de tentatives en cas d'erreur (d√©faut: 3)
- `RETRY_DELAY` : D√©lai entre les tentatives en ms (d√©faut: 2000)

## üìù Notes Importantes

1. **Sauvegarde** : Le script sauvegarde automatiquement sa progression dans `.feu-humain-import-progress.json`
2. **Tri chronologique** : Les messages sont automatiquement tri√©s par date avant l'import
3. **D√©tection de doublons** : Les messages d√©j√† import√©s sont automatiquement ignor√©s
4. **Performance** : L'import est optimis√© pour √©viter les timeouts de Vercel

## üö® En Cas de Probl√®me

Si vous rencontrez des probl√®mes :

1. V√©rifiez les logs du terminal
2. Regardez le fichier `.feu-humain-import-progress.json` pour voir o√π √ßa s'est arr√™t√©
3. Consultez les logs de l'API sur Vercel Dashboard
4. Essayez de r√©duire `CHUNK_SIZE` dans le script (ex: 50 au lieu de 100)

---

**Bon import ! üî•**
