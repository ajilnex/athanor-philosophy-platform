# ğŸ”¥ Guide de rÃ©solution des problÃ¨mes FEU HUMAIN

## Ã‰tat actuel et objectifs

### âœ… Ce qui fonctionne

- Architecture complÃ¨te avec modÃ¨les Prisma
- Interface admin Ã©lÃ©gante avec timeline
- Import incrÃ©mental avec dÃ©tection de doublons
- API routes fonctionnelles

### ğŸ¯ Les 3 objectifs Ã  rÃ©soudre

1. **ProblÃ¨me d'encodage** âœ… (RÃ‰SOLU)
2. **Peupler la base de donnÃ©es en ligne** (EN COURS)
3. **Ajouter les mÃ©dias sur Cloudinary** (Ã€ FAIRE)

---

## ğŸ“ Ã‰tape 1 : Correction de l'encodage (RÃ‰SOLU âœ…)

### ProblÃ¨me identifiÃ©

Les exports Messenger ont un problÃ¨me de double encodage UTF-8 :

- `ÃƒÂ©` au lieu de `Ã©`
- `ÃƒÂ¨` au lieu de `Ã¨`
- `Ã¢â‚¬â„¢` au lieu de `'`
- etc.

### Solution implÃ©mentÃ©e

Un script de nettoyage a Ã©tÃ© crÃ©Ã© : `scripts/clean-messenger-export.ts`

#### Comment l'utiliser :

```bash
# 1. ExÃ©cuter le script de nettoyage
npm run clean:feu-humain

# Le script va :
# - Lire le fichier original : public/FEU HUMAIN/message_1.json
# - CrÃ©er une sauvegarde : message_1_original.json
# - Nettoyer tous les problÃ¨mes d'encodage
# - Sauvegarder le rÃ©sultat : message_1_clean.json
```

#### VÃ©rification :

```bash
# Ouvrir le fichier nettoyÃ© pour vÃ©rifier
cat "public/FEU HUMAIN/message_1_clean.json" | head -n 100

# Ou chercher des patterns spÃ©cifiques
grep -c "ÃƒÂ©" "public/FEU HUMAIN/message_1_clean.json"  # Devrait retourner 0
```

#### AprÃ¨s validation :

```bash
# Si le nettoyage est bon, remplacer l'original
cd "public/FEU HUMAIN"
cp message_1_clean.json message_1.json
```

---

## ğŸš€ Ã‰tape 2 : Import en base de donnÃ©es

### Option A : Via l'interface admin (RECOMMANDÃ‰)

1. **DÃ©marrer le serveur local** :

```bash
npm run db:dev:start  # Lance PostgreSQL Docker
npm run dev           # Lance Next.js
```

2. **Se connecter en admin** :

- Aller sur http://localhost:3000/admin
- Se connecter avec vos identifiants admin

3. **Naviguer vers FEU HUMAIN** :

- Cliquer sur "FEU HUMAIN" dans le menu admin
- Si l'archive n'existe pas, cliquer sur "CrÃ©er l'archive et importer"
- Si elle existe, cliquer sur "Importer des messages"

4. **Uploader le fichier nettoyÃ©** :

- SÃ©lectionner `message_1_clean.json`
- Le systÃ¨me analysera le fichier
- Cliquer sur "CrÃ©er l'archive et importer" ou "Importer X nouveaux messages"

### Option B : Via script direct

```bash
# Utiliser le script d'import existant
npm run import:feu-humain

# Le script va :
# - CrÃ©er l'archive dans PostgreSQL
# - Importer tous les messages par lots de 100
# - CrÃ©er les participants et rÃ©actions
# - RÃ©fÃ©rencer les mÃ©dias (sans upload)
```

### VÃ©rification de l'import :

```bash
# Se connecter Ã  Prisma Studio pour voir les donnÃ©es
npm run db:studio

# Ou vÃ©rifier via l'interface
# http://localhost:3000/admin/feu-humain
```

---

## ğŸ“¤ Ã‰tape 3 : Import en production

### PrÃ©parer le fichier

1. **S'assurer que le fichier est nettoyÃ©** :

```bash
ls -la "public/FEU HUMAIN/"
# VÃ©rifier que message_1_clean.json existe
```

2. **RÃ©duire la taille si nÃ©cessaire** (max 100MB pour Vercel) :

```bash
# VÃ©rifier la taille
du -h "public/FEU HUMAIN/message_1_clean.json"

# Si > 100MB, diviser en plusieurs parties
# ou compresser avec gzip
```

### Import via l'interface de production

1. **Se connecter Ã  l'admin de production** :

```
https://votre-site.vercel.app/admin
```

2. **Naviguer vers FEU HUMAIN** :

- Menu Admin â†’ FEU HUMAIN
- Cliquer sur "Importer des messages"

3. **Uploader et importer** :

- SÃ©lectionner le fichier nettoyÃ©
- Attendre l'analyse (peut prendre 1-2 minutes)
- Cliquer sur "CrÃ©er l'archive et importer"
- L'import peut prendre 10-20 minutes pour ~6000 messages

### Surveillance de l'import

- Garder la page ouverte pendant l'import
- En cas d'erreur timeout, relancer (dÃ©tection automatique des doublons)
- VÃ©rifier les logs dans Vercel Dashboard si problÃ¨me

---

## ğŸ–¼ï¸ Ã‰tape 4 : Upload des mÃ©dias (Ã€ FAIRE)

### StratÃ©gie recommandÃ©e

1. **Phase 1 : RÃ©fÃ©rences en DB** (dÃ©jÃ  fait)
   - Les mÃ©dias sont rÃ©fÃ©rencÃ©s dans `ConversationMedia`
   - Les URLs locales sont stockÃ©es

2. **Phase 2 : Upload Cloudinary** (Ã  implÃ©menter)

CrÃ©er un script `upload-media-cloudinary.ts` :

```typescript
// Pseudo-code du script Ã  crÃ©er
async function uploadMediaToCloudinary() {
  // 1. RÃ©cupÃ©rer tous les ConversationMedia sans cloudinaryUrl
  const mediaToUpload = await prisma.conversationMedia.findMany({
    where: { cloudinaryUrl: null },
  })

  // 2. Pour chaque mÃ©dia
  for (const media of mediaToUpload) {
    // VÃ©rifier si le fichier local existe
    const localPath = `public/FEU HUMAIN/${media.originalUri}`

    // Upload vers Cloudinary
    const result = await cloudinary.uploader.upload(localPath, {
      folder: 'feu-humain',
      resource_type: getResourceType(media.type),
    })

    // Mettre Ã  jour la DB
    await prisma.conversationMedia.update({
      where: { id: media.id },
      data: {
        cloudinaryUrl: result.secure_url,
        cloudinaryPublicId: result.public_id,
      },
    })
  }
}
```

### Configuration Cloudinary

Dans `.env.local` et `.env.production` :

```env
CLOUDINARY_CLOUD_NAME=votre-cloud
CLOUDINARY_API_KEY=votre-api-key
CLOUDINARY_API_SECRET=votre-api-secret
```

---

## ğŸ” Debugging et troubleshooting

### ProblÃ¨mes courants

#### "Archive non trouvÃ©e"

- VÃ©rifier que l'import initial a Ã©tÃ© fait
- Regarder les logs : `npm run db:studio`

#### CaractÃ¨res mal affichÃ©s aprÃ¨s import

- Re-nettoyer le fichier : `npm run clean:feu-humain`
- VÃ©rifier l'encodage : `file -I "public/FEU HUMAIN/message_1.json"`

#### Timeout pendant l'import

- Diviser le fichier en parties plus petites
- Utiliser l'import incrÃ©mental (plusieurs passes)
- Augmenter les timeouts dans `maxDuration` de l'API route

#### MÃ©dias non visibles

- VÃ©rifier que les fichiers sont dans `public/FEU HUMAIN/`
- VÃ©rifier les chemins dans la DB correspondent
- Attendre l'upload Cloudinary (phase 2)

### Commandes utiles

```bash
# Voir les logs de l'application
npm run dev

# Inspecter la base de donnÃ©es
npm run db:studio

# VÃ©rifier l'encodage d'un fichier
file -I fichier.json

# Compter les messages dans le JSON
cat message_1.json | jq '.messages | length'

# Chercher des patterns d'encodage cassÃ©
grep -o "Ãƒ[Â¢Â£Â¤Â¥Â¦Â§Â¨Â©ÂªÂ«Â¬Â­Â®Â¯Â°Â±Â²Â³Â´ÂµÂ¶Â·Â¸Â¹ÂºÂ»Â¼Â½Â¾Â¿Ã€ÃÃ‚ÃƒÃ„Ã…Ã†Ã‡ÃˆÃ‰ÃŠÃ‹ÃŒÃÃÃÃÃ‘Ã’Ã“Ã”Ã•Ã–Ã—Ã˜Ã™ÃšÃ›ÃœÃÃÃŸÃ Ã¡Ã¢Ã£Ã¤Ã¥Ã¦Ã§Ã¨Ã©ÃªÃ«Ã¬Ã­Ã®Ã¯Ã°Ã±Ã²Ã³Ã´ÃµÃ¶Ã·Ã¸Ã¹ÃºÃ»Ã¼Ã½Ã¾Ã¿]" message_1.json | sort | uniq -c
```

---

## âœ… Checklist finale

- [ ] Fichier JSON nettoyÃ© avec `clean:feu-humain`
- [ ] Import testÃ© en local
- [ ] CaractÃ¨res accentuÃ©s s'affichent correctement
- [ ] Import en production rÃ©ussi
- [ ] Archive visible sur `/admin/feu-humain`
- [ ] Timeline fonctionne avec scroll infini
- [ ] Recherche et filtres fonctionnels
- [ ] MÃ©dias rÃ©fÃ©rencÃ©s (phase 1)
- [ ] MÃ©dias uploadÃ©s sur Cloudinary (phase 2 - optionnel)

---

## ğŸ“ Support

En cas de problÃ¨me :

1. VÃ©rifier les logs Vercel
2. Consulter Prisma Studio
3. Regarder la console du navigateur
4. VÃ©rifier que les migrations sont appliquÃ©es

---

_DerniÃ¨re mise Ã  jour : Installation du systÃ¨me de nettoyage d'encodage_
