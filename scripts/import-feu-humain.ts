/**
 * Script d'import de l'archive FEU HUMAIN dans PostgreSQL
 * Optimis√© pour Vercel et production
 *
 * Usage: npm run import:feu-humain
 */

import { PrismaClient } from '@prisma/client'
import fs from 'fs/promises'
import path from 'path'
import { v2 as cloudinary } from 'cloudinary'

const prisma = new PrismaClient()

// Configuration Cloudinary
cloudinary.config({
  cloud_name: process.env.CLOUDINARY_CLOUD_NAME,
  api_key: process.env.CLOUDINARY_API_KEY,
  api_secret: process.env.CLOUDINARY_API_SECRET,
})

interface MessengerExport {
  participants: Array<{ name: string }>
  messages: Array<{
    sender_name: string
    timestamp_ms: number
    content?: string
    photos?: Array<{ uri: string; creation_timestamp?: number }>
    videos?: Array<{ uri: string; thumbnail?: { uri: string } }>
    audio_files?: Array<{ uri: string }>
    reactions?: Array<{ reaction: string; actor: string }>
    type?: string
  }>
  title: string
  is_still_participant?: boolean
  thread_type?: string
  thread_path?: string
}

class FeuHumainImporter {
  private batchSize = 100 // Traiter par lots pour √©viter les timeouts
  private uploadToCloudinary = false // √Ä activer apr√®s tests locaux

  async import(jsonPath: string): Promise<void> {
    console.log('üî• Import FEU HUMAIN dans PostgreSQL')
    console.log('=====================================\n')

    try {
      // 1. Charger le JSON
      console.log('üìñ Chargement du fichier JSON...')
      const rawData = await fs.readFile(jsonPath, 'utf-8')
      const data: MessengerExport = JSON.parse(rawData)
      console.log(`‚úÖ ${data.messages.length} messages charg√©s`)

      // 2. Cr√©er l'archive
      console.log("\nüì¶ Cr√©ation de l'archive...")
      const archive = await this.createArchive(data)
      console.log(`‚úÖ Archive cr√©√©e: ${archive.slug}`)

      // 3. Cr√©er les participants
      console.log('\nüë• Import des participants...')
      const participantsMap = await this.importParticipants(archive.id, data)
      console.log(`‚úÖ ${participantsMap.size} participants import√©s`)

      // 4. Importer les messages par lots
      console.log('\nüí¨ Import des messages...')
      await this.importMessages(archive.id, data, participantsMap)

      // 5. Mettre √† jour les statistiques
      console.log('\nüìä Mise √† jour des statistiques...')
      await this.updateStatistics(archive.id)

      console.log('\n‚ú® Import termin√© avec succ√®s!')
      console.log(`üîó Acc√®s: /admin/feu-humain/${archive.slug}`)
    } catch (error) {
      console.error("‚ùå Erreur lors de l'import:", error)
      throw error
    } finally {
      await prisma.$disconnect()
    }
  }

  private async createArchive(data: MessengerExport) {
    const timestamps = data.messages.map(m => m.timestamp_ms)
    const startDate = new Date(Math.min(...timestamps))
    const endDate = new Date(Math.max(...timestamps))

    return await prisma.conversationArchive.create({
      data: {
        title: data.title || 'FEU HUMAIN',
        slug: 'feu-humain',
        description: 'Archive de la conversation l√©gendaire',
        threadType: data.thread_type,
        participantCount: data.participants.length,
        messageCount: data.messages.length,
        startDate,
        endDate,
        metadata: {
          originalPath: data.thread_path,
          isStillParticipant: data.is_still_participant,
        },
        isPublic: false, // Prot√©g√© par d√©faut
      },
    })
  }

  private async importParticipants(
    archiveId: string,
    data: MessengerExport
  ): Promise<Map<string, string>> {
    const participantsMap = new Map<string, string>()

    // Cr√©er tous les participants
    for (const participant of data.participants) {
      const created = await prisma.conversationParticipant.create({
        data: {
          archiveId,
          name: participant.name,
          messageCount: 0,
        },
      })
      participantsMap.set(participant.name, created.id)
    }

    // Calculer les stats par participant
    const stats = new Map<string, { count: number; first: number; last: number }>()

    for (const message of data.messages) {
      const current = stats.get(message.sender_name) || {
        count: 0,
        first: message.timestamp_ms,
        last: message.timestamp_ms,
      }

      current.count++
      current.first = Math.min(current.first, message.timestamp_ms)
      current.last = Math.max(current.last, message.timestamp_ms)

      stats.set(message.sender_name, current)
    }

    // Mettre √† jour les stats
    for (const [name, id] of participantsMap) {
      const stat = stats.get(name)
      if (stat) {
        await prisma.conversationParticipant.update({
          where: { id },
          data: {
            messageCount: stat.count,
            firstMessageAt: new Date(stat.first),
            lastMessageAt: new Date(stat.last),
          },
        })
      }
    }

    return participantsMap
  }

  private async importMessages(
    archiveId: string,
    data: MessengerExport,
    participantsMap: Map<string, string>
  ): Promise<void> {
    const totalMessages = data.messages.length
    let imported = 0

    // Trier par timestamp pour garder l'ordre chronologique
    const sortedMessages = [...data.messages].sort((a, b) => a.timestamp_ms - b.timestamp_ms)

    // Traiter par lots
    for (let i = 0; i < sortedMessages.length; i += this.batchSize) {
      const batch = sortedMessages.slice(i, i + this.batchSize)

      await prisma.$transaction(async tx => {
        for (const msg of batch) {
          // Cr√©er le message
          const message = await tx.conversationMessage.create({
            data: {
              archiveId,
              participantId: participantsMap.get(msg.sender_name) || null,
              senderName: msg.sender_name,
              content: msg.content || null,
              timestamp: msg.timestamp_ms,
              timestampDate: new Date(msg.timestamp_ms),
              messageType: msg.type || 'text',
              metadata: {
                originalType: msg.type,
              },
            },
          })

          // Ajouter les m√©dias
          if (msg.photos && msg.photos.length > 0) {
            for (const photo of msg.photos) {
              await this.createMedia(tx, message.id, 'photo', photo.uri)
            }
          }

          if (msg.videos && msg.videos.length > 0) {
            for (const video of msg.videos) {
              await this.createMedia(tx, message.id, 'video', video.uri, video.thumbnail?.uri)
            }
          }

          if (msg.audio_files && msg.audio_files.length > 0) {
            for (const audio of msg.audio_files) {
              await this.createMedia(tx, message.id, 'audio', audio.uri)
            }
          }

          // Ajouter les r√©actions
          if (msg.reactions && msg.reactions.length > 0) {
            for (const reaction of msg.reactions) {
              await tx.conversationReaction.create({
                data: {
                  messageId: message.id,
                  participantId: participantsMap.get(reaction.actor) || null,
                  actorName: reaction.actor,
                  reaction: reaction.reaction,
                },
              })
            }
          }
        }
      })

      imported += batch.length
      console.log(
        `  üì• ${imported}/${totalMessages} messages import√©s (${Math.round((imported / totalMessages) * 100)}%)`
      )
    }
  }

  private async createMedia(
    tx: any,
    messageId: string,
    type: string,
    originalUri: string,
    thumbnailUri?: string
  ) {
    const fileName = path.basename(originalUri)

    let cloudinaryUrl = null
    let cloudinaryPublicId = null
    let thumbnailUrl = null

    // Upload vers Cloudinary (d√©sactiv√© par d√©faut pour les tests)
    if (this.uploadToCloudinary) {
      try {
        const localPath = path.join('./public/FEU HUMAIN', originalUri)

        // V√©rifier si le fichier existe localement
        await fs.access(localPath)

        // Mapper le type local au resource_type de Cloudinary
        let resource_type: 'image' | 'video' | 'raw' = 'image'
        if (type === 'video' || type === 'audio') {
          resource_type = 'video'
        } else if (type === 'file') {
          resource_type = 'raw'
        }

        // Upload selon le type
        const uploadOptions = {
          folder: 'feu-humain',
          resource_type: resource_type,
          public_id: `${type}_${messageId}_${Date.now()}`,
        }

        const result = await cloudinary.uploader.upload(localPath, uploadOptions)

        cloudinaryUrl = result.secure_url
        cloudinaryPublicId = result.public_id

        // G√©n√©rer thumbnail pour vid√©os
        if (type === 'video' && !thumbnailUri) {
          thumbnailUrl = cloudinary.url(result.public_id, {
            resource_type: 'video',
            transformation: [{ width: 400, height: 300, crop: 'fill' }, { format: 'jpg' }],
          })
        }
      } catch (error) {
        console.warn(`  ‚ö†Ô∏è Impossible d'uploader ${fileName}:`, error)
      }
    }

    await tx.conversationMedia.create({
      data: {
        messageId,
        type,
        originalUri,
        cloudinaryUrl,
        cloudinaryPublicId,
        thumbnailUrl,
        fileName,
      },
    })
  }

  private async updateStatistics(archiveId: string) {
    const [messageCount, participantCount] = await Promise.all([
      prisma.conversationMessage.count({ where: { archiveId } }),
      prisma.conversationParticipant.count({ where: { archiveId } }),
    ])

    await prisma.conversationArchive.update({
      where: { id: archiveId },
      data: { messageCount, participantCount },
    })
  }
}

// Ex√©cution
async function main() {
  const importer = new FeuHumainImporter()
  const jsonPath = './public/FEU HUMAIN/message_1.json'

  try {
    await importer.import(jsonPath)
  } catch (error) {
    console.error('Erreur fatale:', error)
    process.exit(1)
  }
}

if (require.main === module) {
  main()
}

export { FeuHumainImporter }
